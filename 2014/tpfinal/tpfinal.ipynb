{
 "metadata": {
  "name": "",
  "signature": "sha256:e7751ea715a3353f7e9a1fa4678dea90dadbad7322bd2b8f8f2bfe0cc788c3e9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Trabajo pr\u00e1ctico final: clasificaci\u00f3n de vinos con machine learning\n",
      "===================================================================\n",
      "\n",
      "En este trabajo vamos a utilizar t\u00e9cnicas de machine learning con el objetivo de clasificar vinos a partir de sus componentes qu\u00edmicos y algunas otras caracter\u00edsticas medidas en cada muestra, datos obtenidos de mediciones reales sobre vinos de 3 diferentes cultivadores.\n",
      "\n",
      "El problema:\n",
      "============\n",
      "\n",
      "Se poseen mediciones de distintos qu\u00edmicos y algunos otros aspectos presentes en muestras de vinos provenientes de 3 cultivadores diferentes. Con esta informaci\u00f3n se desea aprender una funci\u00f3n que permita determinar el origen de nuevas muestras de vino, solo a partir de las mediciones de sus componentes.\n",
      "\n",
      "La soluci\u00f3n:\n",
      "============\n",
      "\n",
      "En primer lugar tenemos que determinar si los datos son realmente clasificables. Es decir, tenemos que intentar verificar que realmente se puedan \"separar\" los datos en grupos claramente con curvas. Si los datos est\u00e1n muy \"mezclados\" es probable que no podamos encontrar una funci\u00f3n que los separe con precisi\u00f3n aceptable.\n",
      "\n",
      "Como las entradas tienen 13 dimensiones (los compuestos qu\u00edmicos que tiene cada muestra), no es posible armar un gr\u00e1fico que muestre los puntos con tudos sus datos, y all\u00ed ver su agrupaci\u00f3n. Pero algo que s\u00ed podemos hacer es graficar los datos tomando de a pares de dimensiones, y visualizar esos datos incompletos. Si en algunas de esas visualizaciones los datos son claramente separables, entonces es posible encontrar una funci\u00f3n que clasifique correctamente.\n",
      "\n",
      "Para aprender la funci\u00f3n deseada vamos a intentar utilizar el algoritmo K-Vecinos para clasificaci\u00f3n, implementado en la biblioteca Scikit-Learn. Como el algoritmo requiere que se defina el par\u00e1metro K (la cantidad de vecinos), vamos a evaluar el algoritmo con distintos valores de K y elegir el valor que mejores resultados obtenga.\n",
      "\n",
      "Y para evaluar los resultados vamos a utilizar 3 medidas: precisi\u00f3n (porcentaje de muestras bien clasificadas), accuracy y recall (medidas explicadas en clase, que aseguran que el algoritmo no nos haga \"trampa\" prediciendo siempre las clases m\u00e1s probables).\n",
      "\n",
      "Requerimientos:\n",
      "===============\n",
      "\n",
      "Para poder resolver esta entrega van a requerir las siguientes herramientas instaladas:\n",
      "\n",
      "**Ipython Notebook**\n",
      "\n",
      "La herramienta utilizada para editar y ejecutar este documento.\n",
      "\n",
      "Instalaci\u00f3n en linux: \n",
      "    \n",
      "    sudo pip install \"ipython[notebook]\"\n",
      "\n",
      "Para windows, recomendamos instalarlo utilizando Conda.\n",
      "\n",
      "**Numpy**\n",
      "\n",
      "Biblioteca de python para c\u00e1lculo num\u00e9rico r\u00e1pido (est\u00e1 programada en C en su mayor parte), que vamos a utilizar para armar los arrays de datos de entrada y salida.\n",
      "\n",
      "Instalaci\u00f3n en linux:\n",
      "\n",
      "    sudo apt-get install python-numpy\n",
      "\n",
      "Para windows, recomendamos instalarlo utilizando Conda.\n",
      "\n",
      "**Bokeh**\n",
      "\n",
      "Biblioteca de python para visualizaciones interactivas, que vamos a utilizar para visualizar gr\u00e1ficas.\n",
      "\n",
      "Instalaci\u00f3n en linux: \n",
      "(incluye instalar headers y compiladores necesarios para dependencias de bokeh)\n",
      "\n",
      "    sudo apt-get install python-dev build-essential\n",
      "    sudo pip install bokeh\n",
      "\n",
      "Para windows, recomendamos instalarlo utilizando Conda.\n",
      "\n",
      "**SciKit-Learn**\n",
      "\n",
      "Biblioteca de python para machine learning, que utilizaremos para el algoritmo de clasificaci\u00f3n.\n",
      "\n",
      "Instalaci\u00f3n en linux: \n",
      "\n",
      "    sudo apt-get install python-sklearn\n",
      "\n",
      "Para windows, recomendamos instalarlo utilizando Conda.\n",
      "\n",
      "Ejecuci\u00f3n y entrega:\n",
      "====================\n",
      "\n",
      "Para abrir y ejecutar este notebook, deben bajar los archivos ```tpfinal.ipynb``` y ```wine.data``` del repositorio, y luego desde la consola, posicionarse en la carpeta donde se encuentren los archivos y ejecutar:\n",
      "\n",
      "    ipython notebook\n",
      "    \n",
      "Esto abrir\u00e1 una nueva pesta\u00f1a en el navegador, en la que van a ver listados los notebooks presentes. Haciendo click en ```tpfinal.ipynb``` se abre este mismo notebook, pero ya con capacidad para editarlo y ejecutar las celdas de c\u00f3digo (las celdas se ejecutan eligiendo la celda y presionando ```shift+enter```. Las celdas se editan haci\u00e9ndoles doble click).\n",
      "\n",
      "Sobre este documento deben resolver los ejercicios que se encuentran detallados (incluyen agregar c\u00f3digo para resolver secciones, gr\u00e1ficos, y obtenci\u00f3n de m\u00e9tricas), guardando las modificaciones. Cuando lo consideren terminado, deben subir el ```tpfinal.ipynb``` modificado a sus propios repositorios."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from bokeh.plotting import scatter, line, output_notebook, show, hold, figure\n",
      "from bokeh.objects import Range1d\n",
      "\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score\n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "output_notebook()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "C\u00f3digo de ayuda y ejercicios:\n",
      "=============================\n",
      "\n",
      "Estas son las columnas que tienen nuestros datos de entrada. Son los distintos valores medidos en cada muestra:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium', 'Total phenols', 'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', 'OD280/OD315 of diluted wines', 'Proline'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Estas son las distintas clases que se encuentran en los datos de salida, las etiquetas que vamos a usar para clasificar a cada muestra. Y definimos tambi\u00e9n colores para cada clase, que se usan en las gr\u00e1ficas."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clases = 'cultivador 1', 'cultivador 2', 'cultivador 3'\n",
      "colores_clases = 'red', 'green', 'blue'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lo primero que tenemos que hacer es leer los datos que vamos a usar para entrenar y testear al clasificador, que est\u00e1n en un archivo con formato csv. Los leemos y convertimos a arrays de numpy, que son mucho m\u00e1s eficientes y r\u00e1pidos que usar listas de python normales."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('wine.data') as archivo:\n",
      "    datos_leidos = list(csv.reader(archivo))\n",
      "\n",
      "entradas = np.array([map(float, fila[1:]) for fila in datos_leidos])\n",
      "salidas = np.array([int(fila[0]) - 1 for fila in datos_leidos])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "El conjunto de datos de entrada es una matriz de 178 filas (las 178 muestras de vinos obtenidas), y 13 columnas (features), que son los distintos valores medidos en cada muestra.\n",
      "El conjunto de datos de salida es un vector con las 178 clases correspondientes a cada muestra. Las clases van de 0 a 2."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print entradas.shape \n",
      "print salidas.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Como no es posible graficar las muestras debido a que tienen m\u00e1s de 3 dimensiones, si queremos graficarlas para analizar qu\u00e9 tan separables son, debemos hacerlo tomando de a pares de dimensiones. Por ejemplo, graficar solo las dimensiones \"Malic acid\" y \"Nonflavanoid phenols\".\n",
      "\n",
      "El siguiente gr\u00e1fico hace eso, y como podemos ver, si tomamos solo esas dimensiones los datos no son tan separables por sus clases."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indice_feature1 = 1\n",
      "indice_feature2 = 7\n",
      "\n",
      "salidas_a_colores = [colores_clases[v] for v in salidas]\n",
      "\n",
      "scatter(entradas[:, indice_feature1], \n",
      "        entradas[:, indice_feature2], \n",
      "        color=salidas_a_colores,\n",
      "        title='Separables?',\n",
      "        x_axis_label=features[indice_feature1],\n",
      "        y_axis_label=features[indice_feature2])\n",
      "show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ejercicio 1\n",
      "===========\n",
      "\n",
      "Modificar el c\u00f3digo que grafica las clases en base a dos dimensiones, para que arme un gr\u00e1fico por cada posible par de dimensiones (features).\n",
      "\n",
      "Ejercicio 2\n",
      "===========\n",
      "\n",
      "Viendo todos los gr\u00e1ficos del ejercicio 1, \u00bfalguno de ellos permite saber que los datos son f\u00e1cilmente clasificables (separables)? \u00bfCon cu\u00e1les dimensiones se ve eso? (responder editando esta misma celda)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "\n",
      "En clases aprendimos sobre los riesgos del sobreentrenamiento (overfitting), y que este problema se combate separando nuestros datos en un set de entrenamiento y otro de test. Scikit learn tiene funcionalidad espec\u00edfica para separar sets de datos de esa manera, la funci\u00f3n ```train_test_split```.\n",
      "\n",
      "Ejercicio 3\n",
      "===========\n",
      "\n",
      "Completar la siguiente celda de c\u00f3digo para que las variables contengan los sets generados con la funci\u00f3n ```train_test_split```."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "entradas_entrenamiento, entradas_test, salidas_entrenamiento, salidas_test =  # llamada a train_test_split"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ahora podemos crear un clasificador de tipo K-vecinos, y entrenarlo con los datos del set de entrenamiento. Como sabemos, k-vecinos requiere que se le defina el par\u00e1metro K (la cantidad de vecinos a observar al predecir), y desconocemos un valor adecuado para K. Pero para realizar una prueba inicial, elegimos el valor 1."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clasificador = KNeighborsClassifier(n_neighbors=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Entrenamos el clasificador:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clasificador.fit(entradas_entrenamiento, salidas_entrenamiento)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Y ahora podemos usarlo para predecir salidas a partir de entradas. Vamos a predecir las salidas de las entradas de los dos conjuntos:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "salidas_predichas_entrenamiento = clasificador.predict(entradas_entrenamiento)\n",
      "salidas_predichas_test = clasificador.predict(entradas_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Con las salidas predichas podemos comparar la precisi\u00f3n, accuracy y recall en cada uno de los dos conjuntos, comparando las predicciones con las salidas reales que esper\u00e1bamos:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conjuntos_salidas = (\n",
      "    ('entrenamiento', salidas_entrenamiento, salidas_predichas_entrenamiento),\n",
      "    ('test', salidas_test, salidas_predichas_test),\n",
      ")\n",
      "medidas = (precision_score, accuracy_score, recall_score)\n",
      "\n",
      "for nombre, salidas, salidas_predichas in conjuntos_salidas:\n",
      "    print 'Set de', nombre\n",
      "    for medida in medidas:\n",
      "        print '   ', medida.func_name, ':', medida(salidas, salidas_predichas)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ejercicio 4\n",
      "===========\n",
      "\n",
      "\u00bfPor qu\u00e9 al medir la performance en el conjunto de entrenamiento, las predicciones fueron perfectas? (1.0 en todas las m\u00e9tricas de ese conjunto) (responder editando esta misma celda)\n",
      "\n",
      "---\n",
      "\n",
      "Siendo que el resultado en el conjunto de test (probablemente) no fue tan bueno, nos interesar\u00eda probar con otros valores de K y evaluar la performance con esos otros valores. Y no solo con algunos valores elegidos al azar, sino que nos interesa evaluar el algoritmo para todos los posibles valores de K desde 1 hasta 150.\n",
      "\n",
      "Vamos a crear algunas variables donde ir guardando las m\u00e9tricas para cada valor de K:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precisiones = [0,] * 151\n",
      "accuracies = [0,] * 151\n",
      "recalls = [0,] * 151"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ejercicio 5\n",
      "===========\n",
      "\n",
      "Escribir c\u00f3digo que vaya desde K=1 hasta K=150, y en cada iteraci\u00f3n cree un clasificador con el valor correspondiente de K, lo entrene, lo use para predecir las salidas del conjunto de test, eval\u00fae precisi\u00f3n, accuracy y recall en esas predicciones, y guarde las 3 m\u00e9tricas en las variables anteriores, usando K como \u00edndice. Ej:\n",
      "\n",
      "    precisiones[14] = el n\u00famero que dio la precisi\u00f3n del clasificador con K=12\n",
      "\n",
      "Estas m\u00e9tricas deben ser evaluadas **solo** para el conjunto de test."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# c\u00f3digo que rellena los valores en precisiones, accuracies y recalls    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Con los valores completos, podemos ahora graficar las m\u00e9tricas de performance con respecto a los valores posibles de K:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indice_feature1 = 1\n",
      "indice_feature2 = 7\n",
      "\n",
      "salidas_a_colores = [colores_clases[v] for v in salidas]\n",
      "\n",
      "ks = range(1, 151)\n",
      "\n",
      "datos_medidas = (\n",
      "    (u'Precisi\u00f3n', 'red', precisiones),\n",
      "    (u'Accuracy', 'green', accuracies),\n",
      "    (u'Recall', 'blue', recalls),\n",
      ")\n",
      "\n",
      "figure(title='Valores')\n",
      "hold()\n",
      "\n",
      "for nombre, color, valores in datos_medidas:\n",
      "    line(ks, valores[1:],\n",
      "         color=color,\n",
      "         legend=nombre,\n",
      "         x_axis_label='k')\n",
      "\n",
      "show()\n",
      "hold(False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ejercicio 6\n",
      "===========\n",
      "\n",
      "Habiendo visualizado la performance para los distintos valores de K, \u00bfqu\u00e9 valor de K elegir\u00edan como el m\u00e1s adecuado para utilizar? \u00bfPor qu\u00e9? (responder editando esta misma celda)\n",
      "\n",
      "Ejercicio 7\n",
      "===========\n",
      "\n",
      "El valor de precisi\u00f3n obtenido para ese K, \u00bfes v\u00e1lido como estimado de la precisi\u00f3n que tendr\u00edamos prediciendo futuras muestras que no hayan estado en los datos que utilizamos en esta entrega? \u00bfPor qu\u00e9? \u00bfC\u00f3mo estimar\u00edan dicha precisi\u00f3n? (responder editando esta misma celda)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}